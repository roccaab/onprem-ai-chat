services:
  - type: pserv
    name: llama-api
    runtime: docker
    dockerContext: ./llama
    dockerfilePath: ./llama/Dockerfile
    plan: standard
    region: frankfurt

    disk:
      name: models
      mountPath: /var/models
      sizeGB: 15

    envVars:
      - key: LLAMA_HOST
        value: "0.0.0.0"
      - key: LLAMA_PORT
        value: "8080"
      - key: CTX
        value: "2048"
      - key: THREADS
        value: "4"
      - key: MODEL_DIR
        value: "/var/models"
      - key: MODEL_FILE
        value: "smollm3/SmolLM3-3B-Q4_K_M.gguf"
      - key: MODEL_URL
        sync: false

  - type: web
    name: ai-web
    runtime: docker
    dockerContext: ./web
    dockerfilePath: ./web/Dockerfile
    plan: free
    region: frankfurt
    healthCheckPath: /health

    envVars:
      - key: UPSTREAM_HOSTPORT
        fromService:
          type: pserv
          name: llama-api
          property: hostport
      - key: BASIC_AUTH
        value: "0"
      - key: BASIC_AUTH_USER
        sync: false
      - key: BASIC_AUTH_PASS
        sync: false
